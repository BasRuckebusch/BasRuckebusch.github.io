<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width">
  <title>$1 Recognizer</title>
  <link rel="stylesheet" href="base.css" />
  <link rel="stylesheet" href="transitions.css" />
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
</head>

<body>
  <header>
    <a href="/">
      <h1 id="name" data-swup="1">Bas Ruckebusch</h1>
    </a>
  </header>

  <main id="swup" class="detail transition-main">
    <div class="layout">
      <div class="detail__header">
        <h1>
          $1 Unistroke Recognizer
        </h1>
        <h2>
          <a href="https://github.com/BasRuckebusch/Dollar1UnistrokeRecognizer" target="_blank">Source code</a>
        </h2>
      </div>
      <div class="detail__content">
        <p class="intro">
          This is a unistroke recogniser made in Unity based on <a
            href="http://faculty.washington.edu/wobbrock/pubs/uist-07.01.pdf" target="_blank">this paper</a>.
          <br>
          <br>
          I used it during the creation of <a href="/projects/NDS.html">NDS</a> as the basics of its main mechanic.
        </p>
        <p class="buttons">
          <a href="/projects/index.html" class="button">←  Return to Projects</a>
        </p>
        <p>
          <b>Project Duration:</b><br>
          3 Days<br>
          8 hours per day<br>
          <b>Engine:</b> Unity
        </p>
        <span><img src="/img/D1.gif"></span>
        <p>
          This is my one-dollar universal recognizer, developed in Unity for Hieda no Akyuu's Nocturnal Discordant
          Symposium (NDS). While working on NDS, I came across a research paper that laid the groundwork for the main
          mechanic we aimed to implement. This mechanic relied on users drawing patterns and recognizing them when they
          stopped drawing. To promote fast arcade gameplay, all inputs are singular strokes, so the user could draw
          multiple gestures in quick succession.
        </p>
        <p>
          The recognizer class first normalizes the drawn pattern. This is achieved by resampling the list, ensuring
          points are evenly spaced. For instance, if you ask for 128 points, it guarantees an equal distribution along
          the drawn path.
        </p>
        <p>
          Then, it normalizes rotation, allowing the recognizer to identify the pattern regardless of how or where it
          was drawn. This is accomplished by calculating centroids and determining the angle between the centroid and
          the initial point in the list.
        </p>
        <p>
          The recognizer then scales the entire pattern, almost treating it like an image. It resizes it to a square,
          maintaining a consistent size regardless of the original drawing's proportions. This square shape simplifies
          recognition. <br>
          Finally, it translates the square pattern back to the origin, ensuring all patterns share the same reference
          point. This enhances recognition accuracy and consistency.
        </p>
        <br>
        <p>
          The recognition process involves comparing two sets of values: the input points (from the user's drawing) and
          template points (representing known patterns). Both sets have been normalized. The system calculates the
          distance between corresponding points in these arrays and assigns scores. The template with the highest score
          is chosen, indicating the recognized pattern.
        </p>
        <p>
          Once the template with the highest score is identified, its associated name can be used to trigger various
          actions or behaviours in the program. For instance, if the system recognizes a circle, it can execute the
          corresponding functionality specific to circles.
        </p>
        <p>
          In addition to the recognition process, there's another intriguing aspect to how this system operates. It
          employs a box collider to accurately track the mouse's position. This position data is then translated into a
          hit point, which can be directly applied to the sprite itself. This unique approach involves manipulating
          pixels and the image itself to visualize the recognized patterns. It's a weird and unconventional way of doing
          it (as is the course for most things I wrote for this jam) but one I've grown to enjoy immensely.
        </p>
        <br>
        <p>
          I've gained a deeper understanding of sprites in Unity and how to manipulate them, and I've delved into the
          realm of saving and loading data within Unity. Most of my games before this did not involve data storage; this
          project introduced me to working with unity's resources folder and handling data interchangeably between JSON
          data and in-game functionality, which I found immensely valuable.
        </p>
        <span><img src="/img/Question.gif"></span>
      </div>
    </div>
  </main>

  <nav>
    <a href="/projects">
      <span><img src="/img/projects.png"></span>
      <span>Projects</span>
    </a>
    <a href="/about">
      <span><img src="/img/about.png"></span>
      <span>About</span>
    </a>
    <a href="/links">
      <span><img src="/img/links.png"></span>
      <span>Links</span>
    </a>
    <a href="/resume">
      <span><img src="/img/resume.png"></span>
      <span>Resume</span>
    </a>
  </nav>
</body>

</html>